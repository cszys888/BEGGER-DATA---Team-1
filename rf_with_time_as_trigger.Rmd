---
title: "R Notebook"
output: html_notebook
---

```{r, message=FALSE}
library(data.table)
library(ggplot2)
library(dplyr)
library(knitr)
require(bit64)
library(randomForest)
library(stringr)
library(lubridate)
```

```{r}
#Open and process original data set
df = fread('https://raw.githubusercontent.com/cszys888/BEGGER-DATA---Team-1/master/CloudFactory_DataSet_Accuracy_Prediction.tsv') 
colnames(df)[4] = "keytype"
colnames(df)[5] = "mousemove"
colnames(df)[6] = "mouseclick"
colnames(df)[7] = "duration"
df$keytype[is.na(df$keytype)] = 0
df$mousemove[!is.na(df$mousemove)] = "Yes"
df$mousemove[is.na(df$mousemove)] = "No"
df$mouseclick[!is.na(df$mouseclick)] = "Yes"
df$mouseclick[is.na(df$mouseclick)] = "No"

#------------------------------------------------------------------------------------------
#Open and process additional info
  #Reformat the education and gender info
worker_profile = fread('https://raw.githubusercontent.com/cszys888/BEGGER-DATA---Team-1/master/receipt_worker_profile.tsv') 
academic_degree = worker_profile$academic_degree
master_sign = str_detect(academic_degree, "Master")
bachelor_sign = str_detect(academic_degree, "Bachelor")
higher_sign = str_detect(academic_degree, "Higher")
secondary_sign = str_detect(academic_degree, "Secondary")
na_sign = !str_detect(academic_degree, " ")
worker_profile$academic_degree[master_sign] = "master"
worker_profile$academic_degree[(!master_sign)&(bachelor_sign)] = "bachelor"
worker_profile$academic_degree[(!master_sign)&(!bachelor_sign)&(higher_sign)] = "highersecondary"
worker_profile$academic_degree[(!master_sign)&(!bachelor_sign)&(!higher_sign)&(secondary_sign)] = "secondary"
worker_profile$academic_degree[na_sign] = "na"
worker_profile$academic_degree = factor(worker_profile$academic_degree, 
                                           levels = c("master", "bachelor",
                                                      "highersecondary", "secondary",
                                                      "na"))
worker_profile$gender = factor(worker_profile$gender, levels = c("Male", "Female"))
str(worker_profile)
worker_profile = worker_profile %>%
  slice(-(90:93))
present_time = Sys.time()
present_time.poslt = as.POSIXlt(present_time, tz = "America/New_York")
onboardtime = worker_profile$onbarded_date
onboardtime.posix = as.POSIXct(onboardtime, format = "%Y-%m-%d %H:%M:%S")
onboardtime.poslt = as.POSIXlt(onboardtime, tz = "America/New_York")
onboard_duration = (present_time.poslt$year - onboardtime.poslt$year) *12 +
  (present_time.poslt$mon - onboardtime.poslt$mon)
worker_profile$onboard_duration = onboard_duration
worker_profile$age = 2017 - worker_profile$birth_year
worker_profile = worker_profile %>%
  select(-onbarded_date, -birth_year)

#join worker_profile with df
dt1 = inner_join(df, worker_profile)

#------------------------------------------------------------------------------------------
#calculate the average duration for one task
duration_stat = dt1 %>%
  group_by(task_id) %>%
  summarise(duration = duration[1])
summary(duration_stat)

#calculate the relative time of each operation
dt1 = dt1 %>%
  group_by(task_id) %>%
  mutate(rela_time = (timestamp - timestamp[1])/1000)

#add the condition trasferring indicator
#dt1$keytype_new = 4
#dt1$keytype_new[2:nrow(dt1)] = dt1$keytype[1:nrow(dt1)-1]
#dt1$mousemove_new = "No"
#dt1$mousemove_new[2:nrow(dt1)] = dt1$mousemove[1:nrow(dt1)-1]
#dt1$mouseclick_new = "No"
#dt1$mouseclick_new[2:nrow(dt1)] = dt1$mouseclick[1:nrow(dt1)-1]
#dt1 = dt1 %>%
#  group_by(task_id) %>%
#  mutate(key_ind = ifelse(keytype == keytype_new, 0, 1),
#         mouseclick_ind = ifelse(mouseclick == mouseclick_new, 0, 1),
#         mousemove_ind = ifelse(mousemove == mousemove_new, 0, 1))
```



#Full Time Model
```{r}
dt2 = dt1 %>%
  group_by(task_id) %>%
  summarise(duration = duration[1],
            total_op = sum(mousemove == "Yes") + sum(mouseclick == "Yes") + sum(keytype != 0),
            count_mousemove = sum(mousemove == "Yes")/total_op,
            count_mouseclick = sum(mouseclick == "Yes")/total_op,
            key1 = sum(keytype == 1)/total_op,
            key2 = sum(keytype == 2)/total_op,
            key3 = sum(keytype == 3)/total_op,
            key4 = sum(keytype == 4)/total_op,
            key5 = sum(keytype == 5)/total_op,
            key6 = sum(keytype == 6)/total_op,
            key7 = sum(keytype == 7)/total_op,
            key8 = sum(keytype == 8)/total_op,
            key9 = sum(keytype == 9)/total_op,
            key10 = sum(keytype == 10)/total_op,
            key11 = sum(keytype == 11)/total_op,
            key12 = sum(keytype == 12)/total_op,
            accuracy = accuracy[1],
            worker_id = worker_id[1],
            gender = gender[1],
            academic_degree = academic_degree[1],
            onboard_duration = onboard_duration[1],
            age = age[1])%>%
  select(-task_id, -worker_id, -total_op) %>%
  mutate(accuracy = (accuracy == 1)) 
dt2$accuracy = as.factor(dt2$accuracy)

#randomforest binary classification
#divide data into training and testing
set.seed(2000)
index = sample(1:nrow(dt2), round(0.5*nrow(dt2)))
train = dt2[index,]
test = dt2[-index,]

#build model on training data
n = names(dt2)
f = as.formula(paste("accuracy~", paste(n[!n %in% "accuracy"], collapse = "+")))
rf2 = randomForest(data = train, f, importance = TRUE)
predict_train = predict(rf2)
train_table2 = table(train$accuracy, predict_train)
kable(train_table2)
train_accurate2 = sum(diag(train_table2))/nrow(train);train_accurate2

#test 
predict_test = predict(rf2, newdata = test, type = "response")
test_table2 = table(test$accuracy, predict_test)
kable(test_table2)
test_accurate2 = sum(diag(test_table2))/nrow(test);test_accurate2

#variable importance
varImpPlot(rf2)

```

#Evaluate the Full Model (Make Sure to Run "Full Operation Model" Chunk First)
```{r}
#Calculate Information Gain
matrix_train2=train_table2/sum(train_table2)
Entro_Condi = -sum(matrix_train2[1,])*log2(sum(matrix_train2[1,])) - sum(matrix_train2[2,])*log2(sum(matrix_train2[2,]))
Entro_Class = -sum(matrix_train2[,1])*log2(sum(matrix_train2[,1])) - sum(matrix_train2[,2])*log2(sum(matrix_train2[,2]))
Entro_Matri = -sum(matrix_train2[1,1])*log2(sum(matrix_train2[1,1])) - sum(matrix_train2[1,2])*log2(sum(matrix_train2[1,2])) - sum(matrix_train2[2,1])*log2(sum(matrix_train2[2,1])) - sum(matrix_train2[2,2])*log2(sum(matrix_train2[2,2]))
PIG_2_train = (Entro_Condi + Entro_Class - Entro_Matri)/Entro_Condi;PIG_2_train
  #---↑Train---↓Test---
matrix_test2=test_table2/sum(test_table2)
Entro_Condi = -sum(matrix_test2[1,])*log2(sum(matrix_test2[1,])) - sum(matrix_test2[2,])*log2(sum(matrix_test2[2,]))
Entro_Class = -sum(matrix_test2[,1])*log2(sum(matrix_test2[,1])) - sum(matrix_test2[,2])*log2(sum(matrix_test2[,2]))
Entro_Matri = -sum(matrix_test2[1,1])*log2(sum(matrix_test2[1,1])) - sum(matrix_test2[1,2])*log2(sum(matrix_test2[1,2])) - sum(matrix_test2[2,1])*log2(sum(matrix_test2[2,1])) - sum(matrix_test2[2,2])*log2(sum(matrix_test2[2,2]))
PIG_2_test = (Entro_Condi + Entro_Class - Entro_Matri)/Entro_Condi;PIG_2_test

#------------------------------------------------------------------------------------------
#Analyze added value
train_detail2 = data.frame(train$accuracy, predict_train,train$duration)
test_detail2 = data.frame(test$accuracy, predict_test,test$duration)
colnames(train_detail2)[3] = "Task_Duration"
colnames(test_detail2)[3] = "Task_Duration"

  #Create confision matrix lable and time cost
    #Train Set
train_detail2 = train_detail2 %>% 
    #To lable confusion matrix
  mutate(TN = ((train.accuracy=="TRUE")*(predict_train=="TRUE")),
         FN = ((train.accuracy=="FALSE")*(predict_train=="TRUE")),
         FP = ((train.accuracy=="TRUE")*(predict_train=="FALSE")),
         TP = ((train.accuracy=="FALSE")*(predict_train=="FALSE"))) %>%
  select(-train.accuracy,-predict_train) %>%
    #To get correspondent time cost
  mutate(Cost_Benchmark = 3*Task_Duration*(TP+FN)+2*Task_Duration*(TN+FP),
         Cost_Omniscient = 2*Task_Duration*(TP+FN)+1*Task_Duration*(TN+FP),
         Cost_Model_ExcludingM = 2*Task_Duration*(TP+FP)+Task_Duration*(TN+FN))
#Test Set
test_detail2 = test_detail2 %>% 
      #To lable confusion matrix
  mutate(TN = ((test.accuracy=="TRUE")*(predict_test=="TRUE")),
         FN = ((test.accuracy=="FALSE")*(predict_test=="TRUE")),
         FP = ((test.accuracy=="TRUE")*(predict_test=="FALSE")),
         TP = ((test.accuracy=="FALSE")*(predict_test=="FALSE"))) %>%
  select(-test.accuracy,-predict_test) %>%
      #To get correspondent time cost
  mutate(Cost_Benchmark = 3*Task_Duration*(TP+FN)+2*Task_Duration*(TN+FP),
         Cost_Omniscient = 2*Task_Duration*(TP+FN)+1*Task_Duration*(TN+FP),
         Cost_Model_ExcludingM = 2*Task_Duration*(TP+FP)+Task_Duration*(TN+FN))

#Time consumption PER EVENT when it is (double typing)/(Somehow omniscient)/(Using predictive model)
#Caution: Variables in this session share names for in different chunk (As they are just interim variable, so I do not want to bother...)
#Train Set
Double_Typing_Cost_a = mean(train_detail2$Cost_Benchmark);#Double_Typing_Cost_a
Omniscient_Cost_a = mean(train_detail2$Cost_Omniscient);#Omniscient_Cost_a
Model_Cost1_a = mean(train_detail2$Cost_Model_ExcludingM);#Model_Cost1_a
M_counts_a = mean(train_detail2$FN)
    #Test Set
Double_Typing_Cost_e = mean(test_detail2$Cost_Benchmark);#Double_Typing_Cost_e
Omniscient_Cost_e = mean(test_detail2$Cost_Omniscient);#Omniscient_Cost_e
Model_Cost1_e = mean(test_detail2$Cost_Model_ExcludingM);#Model_Cost1_e
M_counts_e = mean(test_detail2$FN)

#final result
result_full = data.frame(train_accuracy = train_accurate2,
                         train_PIG = PIG_2_train,
                         train_general_cost = 1/M_counts_a,
                         train_double_typing_cost = ((Double_Typing_Cost_a - Model_Cost1_a)/M_counts_a),
                         test_accuracy = test_accurate2,
                         test_PIG = PIG_2_test,
                         test_general_cost = 1/M_counts_e,
                         test_double_typing_cost = ((Double_Typing_Cost_e - Model_Cost1_e)/M_counts_e),
                         train_e = train_table2[1,1],
                         train_f = train_table2[1,2],
                         train_g = train_table2[2,1],
                         train_h = train_table2[2,2],
                         test_e = test_table2[1,1],
                         test_f = test_table2[1,2],
                         test_g = test_table2[2,1],
                         test_h = test_table2[2,2])
result_full
```

#loop of time trigger model
```{r}
dt3 = dt1
result_trigger = data.frame(time_trigger = integer(),
                            train_accuracy = double(),
                            train_PIG = double(),
                            # train_general_cost = double(),
                            # train_double_typing_cost = double(),
                            test_accuracy = double(),
                            test_PIG = double(),
                            # test_general_cost = double(),
                            # test_double_typing_cost = double(),
                            train_e = integer(),
                            train_f = integer(),
                            train_g = integer(),
                            train_h = integer(),
                            test_e = integer(),
                            test_f = integer(),
                            test_g = integer(),
                            test_h = integer(),
                            MA_Should_larger = integer(),
                            Breakeven_MA = double(),
                            MB_Should_larger =integer(),
                            Breakeven_MB = double(),
                            MAT_Should_larger = integer(),
                            Breakeven_MAT = double(),
                            MBT_Should_larger = integer(),
                            Breakeven_MBT = double())

for (i in 1:50) {
  dt3 = dt3 %>%
    mutate(keep = ifelse(rela_time <= i, 1, 0))
  
  dt3_keep = dt3 %>%
    filter(keep == 1) %>%
    select(-keep)
  
   #This ia a variable that need to be updated with a different trigger because I do not want to bother naming them   seerately
  Duration_full = dt3_keep %>%
    group_by(task_id) %>%
    summarise(duration = duration[1]) 
  
  dt3_keep = dt3_keep %>%
    group_by(task_id) %>%
    summarise(duration = duration[1],
              duration_to_now = max(rela_time),
              total_op = sum(mousemove == "Yes") + sum(mouseclick == "Yes") + sum(keytype != 0),
              count_mousemove = sum(mousemove == "Yes")/total_op,
              count_mouseclick = sum(mouseclick == "Yes")/total_op,
              key1 = sum(keytype == 1)/total_op,
              key2 = sum(keytype == 2)/total_op,
              key3 = sum(keytype == 3)/total_op,
              key4 = sum(keytype == 4)/total_op,
              key5 = sum(keytype == 5)/total_op,
              key6 = sum(keytype == 6)/total_op,
              key7 = sum(keytype == 7)/total_op,
              key8 = sum(keytype == 8)/total_op,
              key9 = sum(keytype == 9)/total_op,
              key10 = sum(keytype == 10)/total_op,
              key11 = sum(keytype == 11)/total_op,
              key12 = sum(keytype == 12)/total_op,
              accuracy = accuracy[1],
              worker_id = worker_id[1],
              gender = gender[1],
              academic_degree = academic_degree[1],
              onboard_duration = onboard_duration[1],
              age = age[1])%>%
    select(-task_id, -worker_id, -total_op) %>%
    mutate(accuracy = (accuracy == 1))
  dt3_keep$accuracy = as.factor(dt3_keep$accuracy)
  
  #randomforest binary classification
  #divide data into training and testing
  set.seed(2000)
  index3 = sample(1:nrow(dt3_keep), round(0.5*nrow(dt3_keep)))
  train3 = dt3_keep[index3,]
  test3 = dt3_keep[-index3,]
  
  #build model on training data
  n3 = names(dt3_keep)
  f3 = as.formula(paste("accuracy~", paste(n3[!n3 %in% "accuracy"], collapse = "+")))
  rf3 = randomForest(data = train3,
                        f3, importance = TRUE)
  predict_train3 = predict(rf3)
  train_table3 = table(train3$accuracy, predict_train3)
  kable(train_table3)
  train_accurate3 = sum(diag(train_table3))/nrow(train3);train_accurate3
  
  #test 
  predict_test3 = predict(rf3, newdata = test3, type = "response")
  test_table3 = table(test3$accuracy, predict_test3)
  kable(test_table3)
  test_accurate3 = sum(diag(test_table3))/nrow(test);test_accurate3

  #Calculate Information Gain
  matrix_train3=train_table3/sum(train_table3)
  Entro_Condi = -sum(matrix_train3[1,])*log2(sum(matrix_train3[1,])) -   sum(matrix_train3[2,])*log2(sum(matrix_train3[2,]))
  Entro_Class = -sum(matrix_train3[,1])*log2(sum(matrix_train3[,1])) -   sum(matrix_train3[,2])*log2(sum(matrix_train3[,2]))
  Entro_Matri = -sum(matrix_train3[1,1])*log2(sum(matrix_train3[1,1])) -   sum(matrix_train3[1,2])*log2(sum(matrix_train3[1,2])) - sum(matrix_train3[2,1])*log2(sum(matrix_train3[2,1])) -   sum(matrix_train3[2,2])*log2(sum(matrix_train3[2,2]))
  PIG_3_train = (Entro_Condi + Entro_Class-Entro_Matri)/Entro_Condi;PIG_3_train
    #---↑Train---↓Test---
  matrix_test3=test_table3/sum(test_table3)
  Entro_Condi = -sum(matrix_test3[1,])*log2(sum(matrix_test3[1,])) - sum(matrix_test3[2,])*log2(sum(matrix_test3[2,]))
  Entro_Class = -sum(matrix_test3[,1])*log2(sum(matrix_test3[,1])) - sum(matrix_test3[,2])*log2(sum(matrix_test3[,2]))
  Entro_Matri = -sum(matrix_test3[1,1])*log2(sum(matrix_test3[1,1])) -   sum(matrix_test3[1,2])*log2(sum(matrix_test3[1,2])) - sum(matrix_test3[2,1])*log2(sum(matrix_test3[2,1])) -   sum(matrix_test3[2,2])*log2(sum(matrix_test3[2,2]))
  PIG_3_test = (Entro_Condi + Entro_Class - Entro_Matri)/Entro_Condi;PIG_3_test
  
  #------------------------------------------------------------------------------------------
  #Analyze added value
  train_detail3 = data.frame(train3$accuracy, predict_train3, train3$duration, train3$duration_to_now)
  test_detail3 = data.frame(test3$accuracy, predict_test3, test3$duration, test3$duration_to_now)
  colnames(train_detail3)[3] = "Task_Duration"
  colnames(test_detail3)[3] = "Task_Duration"
  colnames(train_detail3)[4] = "Duration_Till_Trigger"
  colnames(test_detail3)[4] = "Duration_Till_Trigger"
  
    #Create confision matrix lable and time cost
      #Train Set
  # train_detail3 = train_detail3 %>% 
  #   #To lable confusion matrix
  #   mutate(TN = ((train3.accuracy=="TRUE")*(predict_train3=="TRUE")),
  #          FN = ((train3.accuracy=="FALSE")*(predict_train3=="TRUE")),
  #          FP = ((train3.accuracy=="TRUE")*(predict_train3=="FALSE")),
  #          TP = ((train3.accuracy=="FALSE")*(predict_train3=="FALSE"))) %>%
  #   select(-train3.accuracy,-predict_train3) %>% 
  #   #To get correspondent time cost
  #   mutate(Cost_Benchmark = 3*Task_Duration*(TP+FN) + 2*Task_Duration*(TN+FP),
  #          Cost_Omniscient = 2*Task_Duration*(TP+FN) + 1*Task_Duration*(TN+FP),
  #          Cost_Model_ExcludingM = Task_Duration + Duration_Till_Trigger*(TP+FP))
  # 

  #       #Test Set
  # test_detail3 = test_detail3 %>% 
  #   #To lable confusion matrix
  #   mutate(TN = ((test3.accuracy=="TRUE")*(predict_test3=="TRUE")),
  #          FN = ((test3.accuracy=="FALSE")*(predict_test3=="TRUE")),
  #          FP = ((test3.accuracy=="TRUE")*(predict_test3=="FALSE")),
  #          TP = ((test3.accuracy=="FALSE")*(predict_test3=="FALSE"))) %>%
  #   select(-test3.accuracy,-predict_test3) %>%
  #   #To get correspondent time cost
  #   mutate(Cost_Benchmark = 3*Task_Duration*(TP+FN) + 2*Task_Duration*(TN+FP),
  #          Cost_Omniscient = 2*Task_Duration*(TP+FN) + Task_Duration*(TN+FP),
  #          Cost_Model_ExcludingM = Task_Duration*(TP+FP+TN+FN) + Duration_Till_Trigger*(TP+FP))

  CR = 0.5
  train_alt = data.frame(train3$accuracy, predict_train3, train3$duration, train3$duration_to_now)
  colnames(train_alt)[3] = "Task_Duration"
  colnames(train_alt)[4] = "Duration_Till_Trigger"


  train_alt = train_alt %>%
    mutate (TN = ((train3.accuracy=="TRUE")*(predict_train3=="TRUE")),
           FN = ((train3.accuracy=="FALSE")*(predict_train3=="TRUE")),
           FP = ((train3.accuracy=="TRUE")*(predict_train3=="FALSE")),
           TP = ((train3.accuracy=="FALSE")*(predict_train3=="FALSE")),
           Triggered = (Task_Duration>=i),
           Overtrigger = (Task_Duration<i))  %>%
    select(-train3.accuracy,-predict_train3)   %>% 
    mutate(  CostA1 = 2*Task_Duration,
             CostA2 = 0.08*(TP+FN),
             CostB1 = 3*Task_Duration,
             CostB2 = 0.08*0.08*(TP+TN),
             CostC1 = Task_Duration*(2+(TP+FP)*1)+Triggered*i,
             CostC2 = (Triggered*((Task_Duration-CR*i)/(Task_Duration)) + Overtrigger*1)*(TP+TN)*(0.08*0.08))
    dir_MA = ifelse(mean(train_alt$CostC2)-mean(train_alt$CostA2)>0,0,1);dir_MA
    Breakeven_MA = (mean(train_alt$CostA1)-mean(train_alt$CostC1))/(mean(train_alt$CostC2)-mean(train_alt$CostA2));Breakeven_MA
    dir_MB = ifelse(mean(train_alt$CostC2)-mean(train_alt$CostB2)>0,0,1);dir_MB
    Breakeven_MB = (mean(train_alt$CostB1)-mean(train_alt$CostC1))/(mean(train_alt$CostC2)-mean(train_alt$CostB2));Breakeven_MB

  test_alt = data.frame(test3$accuracy, predict_test3, test3$duration, test3$duration_to_now)
  colnames(test_alt)[3] = "Task_Duration"
  colnames(test_alt)[4] = "Duration_Till_Trigger"

  test_alt = test_alt %>%
    mutate (TN = ((test3.accuracy=="TRUE")*(predict_test3=="TRUE")),
           FN = ((test3.accuracy=="FALSE")*(predict_test3=="TRUE")),
           FP = ((test3.accuracy=="TRUE")*(predict_test3=="FALSE")),
           TP = ((test3.accuracy=="FALSE")*(predict_test3=="FALSE")),
           Triggered = (Task_Duration>=i),
           Overtrigger = (Task_Duration<i))  %>%
    select(-test3.accuracy,-predict_test3)   %>% 
    mutate(  CostA1 = 2*Task_Duration,
             CostA2 = 0.08*(TP+FN),
             CostB1 = 3*Task_Duration,
             CostB2 = 0.08*0.08*(TP+TN),
             CostC1 = Task_Duration*(2+(TP+FP)*1)+Triggered*i,
             CostC2 = (Triggered*((Task_Duration-CR*i)/(Task_Duration)) + Overtrigger*1)*(TP+TN)*(0.08*0.08))
    dir_MAT = ifelse(mean(test_alt$CostC2)-mean(test_alt$CostA2)>0,0,1);dir_MAT
    Breakeven_MAT = (mean(test_alt$CostA1)-mean(test_alt$CostC1))/(mean(test_alt$CostC2)-mean(test_alt$CostA2));Breakeven_MAT 
    dir_MBT = ifelse(mean(test_alt$CostC2)-mean(test_alt$CostB2)>0,0,1);dir_MBT
    Breakeven_MBT = (mean(train_alt$CostA1)-mean(train_alt$CostC1))/(mean(train_alt$CostC2)-mean(train_alt$CostA2));Breakeven_MBT




  
    #Time consumption PER EVENT when it is (double typing)/(Somehow omniscient)/(Using predictive model)
    #Caution: Variables created in this session share names for in different chunk (As they are just interim variable,   so I do not want to bother...)
      #Train Set
  # Double_Typing_Cost_a = mean(train_detail3$Cost_Benchmark);Double_Typing_Cost_a
  # Omniscient_Cost_a = mean(train_detail3$Cost_Omniscient);Omniscient_Cost_a
  # Model_Cost1_a = mean(train_detail3$Cost_Model_ExcludingM);Model_Cost1_a
  # M_counts_a = mean(train_detail3$FN)
  #     #Test Set
  # Double_Typing_Cost_e = mean(test_detail3$Cost_Benchmark);Double_Typing_Cost_e
  # Omniscient_Cost_e = mean(test_detail3$Cost_Omniscient);Omniscient_Cost_e
  # Model_Cost1_e = mean(test_detail3$Cost_Model_ExcludingM);Model_Cost1_e
  # M_counts_e = mean(test_detail3$FN)
  
  #final result for time trigger i
  result_tmp = data.frame(time_trigger = i,
                          train_accuracy = train_accurate3,
                          train_PIG = PIG_3_train,
                          # train_general_cost = 1/M_counts_a,
                          # train_double_typing_cost = ((Double_Typing_Cost_a - Model_Cost1_a)/M_counts_a),
                          test_accuracy = test_accurate3,
                          test_PIG = PIG_3_test,
                          # test_general_cost = 1/M_counts_e,
                          # test_double_typing_cost = ((Double_Typing_Cost_e - Model_Cost1_e)/M_counts_e),
                          train_e = train_table3[1,1],
                          train_f = train_table3[1,2],
                          train_g = train_table3[2,1],
                          train_h = train_table3[2,2],
                          test_e = test_table3[1,1],
                          test_f = test_table3[1,2],
                          test_g = test_table3[2,1],
                          test_h = test_table3[2,2],
                          MA_Should_larger = dir_MA,
                          Breakeven_MA = Breakeven_MA,
                          MB_Should_larger =dir_MB,
                          Breakeven_MB = Breakeven_MB,
                          MAT_Should_larger = dir_MAT,
                          Breakeven_MAT = Breakeven_MAT,
                          MBT_Should_larger = dir_MBT,
                          Breakeven_MBT = Breakeven_MBT)
  result_trigger[i,] = result_tmp
  print(i)
}

#Base on the assumption that:
  #1. P(incorrect-out|receipt-incorrect) = 0.08

  #2. Cost to Validate(N) = Cost to Type = Cost to retype

  #3. There is a for 0.52*0.48 = 0.2496 probability that the double-typing model sends a receipt to re-type when:
    #The first type is correct and the (first) valiudation is incorrect

  #4. Once it goes to the re-type after validation, the retype procedure will not encounter the FP problem (i.e. Retype always gives out a ferfect typing)
    #Made this assumption because
      # a. The probability that retype causes FN is about a*p^2+a*p^3+a*p4+... if you want to calculate 
      # b. The probability that retype causes FP is about a*b^2+a*b^3+a*b4+... if you want to calculate
    #But in the real world the cloudfactory is not idiot, a receipt keeps ummatching will end up with a manual profread not endless retyping

colnames(result_trigger)[1] = "trigger"
# Ti = mean(dt2$duration)
# result_trigger = result_trigger %>%
#   mutate(e0 = train_e/(train_e + train_f + train_g + train_h),  
#          f0 = train_f/(train_e + train_f + train_g + train_h), 
#          g0 = train_g/(train_e + train_f + train_g + train_h),
#          h0 = train_h/(train_e + train_f + train_g + train_h),
#          e1 = test_e/(train_e + train_f + train_g + train_h),
#          f1 = test_f/(train_e + train_f + train_g + train_h),
#          g1 = test_g/(train_e + train_f + train_g + train_h),
#          h1 = test_h/(train_e + train_f + train_g + train_h),
#          a0 = e0+f0,
#          b0 = g0+f0,
#          c0 = e0+g0,
#          d0 = f0+h0,
#          a1 = e1+f1,
#          b1 = g1+f1,
#          c1 = e1+g1,
#          d1 = f1+h1,
#          trigger = trigger,
#          Train = (c0*trigger-(1.6912-0.92*a0-0.48*b0)*Ti)/(0.0384-0.08*(e0/c0 + f0/d0)),
#          Test = (c1*trigger-(1.6912-0.92*a1-0.48*b1)*Ti)/(0.0384-0.08*(e1/c1 + f1/d1)))
# 
# ggplot(data = Breakeven_FN, aes(x = trigger, y = Train)) + 
#   geom_point() +
#   geom_line()+
#   geom_smooth()
# 
# ggplot(data = Breakeven_FN, aes(x = trigger, y = Test)) + 
#   geom_point() +
#   geom_line()+
#   geom_smooth()

ggplot(data = result_trigger, aes(x = trigger, y = Breakeven_MA)) +
  geom_point() +
  geom_line()+
  geom_smooth()

ggplot(data = result_trigger, aes(x = trigger, y = Breakeven_MB)) +
  geom_point() +
  geom_line()+
  geom_smooth()

```

```{r}
write.csv(result_full, file = "result_full.csv")
write.csv(result_trigger, file = "result_trigger_with_CR.csv")
```

```{r}
which(result_trigger$train_general_cost == max(result_trigger$train_general_cost))
which(result_trigger$train_double_typing_cost == max(result_trigger$train_double_typing_cost))
which(result_trigger$test_general_cost == max(result_trigger$test_general_cost))
which(result_trigger$test_double_typing_cost == max(result_trigger$test_double_typing_cost))
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

ggplot(data = result_trigger) + 
  geom_point(aes(x = time_trigger, y = train_accuracy), colour = "red") +
  geom_line(aes(x = time_trigger, y = train_accuracy), colour = "red") +
  geom_point(aes(x = time_trigger, y = test_accuracy), colour = "blue") +
  geom_line(aes(x = time_trigger, y = test_accuracy), colour = "blue") +
```